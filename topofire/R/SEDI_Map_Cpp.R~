## LOAD THE REQUIRED LIBRARYS
library(raster)
library(tictoc)
library(doParallel)
library(foreach)
library(parallel)
library(dplyr)
library(stringr)

#define directories
work.dir = "/mnt/DataDrive2/data/drought_indices/sedi/"
git.dir = '/home/zhoylman/drought_indicators/topofire/R/'
precip.climatology.dir = "/mnt/DataDrive2/data/drought_indices/maca/precip_2.5km"
def.climatology.dir = "/mnt/DataDrive2/data/drought_indices/historical_2p5km/DEF"
def.current.dir = "/mnt/DataDrive2/data/airtemp_realtime/water_balance/2pt5km"
cpp.dir = "/home/zhoylman/drought_indicators/topofire/cpp/"

write.dir = paste0(work.dir,"current/")
archive.dir = paste0(work.dir,"archive/")
dir.create(write.dir)
dir.create(archive.dir)

#import functions
source(paste0(git.dir, "fdates.R"))
source(paste0(git.dir, "sedi_fun.R"))

#parse precip
precip.files = list.files(precip.climatology.dir, pattern = ".tif$", full.names = T)

#parse def
def.files.historical = list.files(def.climatology.dir, pattern = ".tif$", full.names = T)
def.files.current = list.files(def.current.dir, pattern = glob2rx("*et0*.tif$*"), full.names = T)
def.files.current = def.files.current[str_detect(def.files.current,paste(c(seq(2019,2100,1)),collapse = '|'))] #will run till 2100

#combine def
def.files = c(def.files.historical, def.files.current)

#compute time from files
def.time = fdates(def.files)
precip.time = fdates(precip.files)

#match time series
def.files.match = def.files[def.time %in% precip.time]
precip.files.match = precip.files[precip.time %in% def.time]

#compute new time from files
def.time = fdates(def.files.match)
precip.time = fdates(precip.files.match)
time_fdates = fdates(precip.files.match)
time = data.frame(datetime = as.Date(fdates(def.files.match), format = "%Y%m%d"))
time$day = strftime(time$datetime,"%m-%d")

#designate time scale
time_scale = c(30, 60, 90, 180, 360)

for(t in 1:length(time_scale)){
  dir.create(paste0(work.dir, "tmp_dir_def/"))
  tmp.dir.def <- paste0(work.dir, "tmp_dir_def/", time_scale[t], "_days/")
  dir.create(tmp.dir.def)
  
  #calcualte run time
  tic()
  
  #compute time breaks (indexes)
  first_date_breaks = which(time$day == time$day[length(time$datetime)])
  second_date_breaks = first_date_breaks-(time_scale[t]-1)
  
  #if there are negative indexes remove last year (incomplete data range)
  #change this to remove all indexes from both vectors that are negative
  if(!all(second_date_breaks < 0)){
    pos_index = which(second_date_breaks > 0)
    first_date_breaks = first_date_breaks[c(pos_index)]
    second_date_breaks = second_date_breaks[c(pos_index)]
  }
  
  #create slice vectors and group by vectors
  for(j in 1:length(first_date_breaks)){
    if(j == 1){
      slice_vec = seq(second_date_breaks[j],first_date_breaks[j], by = 1)
      group_by_vec = rep(j,(first_date_breaks[j] - second_date_breaks[j]+1))
    }
    else{
      slice_vec = append(slice_vec, seq(second_date_breaks[j],first_date_breaks[j], by = 1))
      group_by_vec = append(group_by_vec, rep(j,(first_date_breaks[j] - second_date_breaks[j]+1)))
    }
  }
  
  ########################################
  ###   C++ METOHD FOR SUMMING GRIDS  ####
  ########################################
  
  cl = makeCluster(20)
  registerDoParallel(cl)
  
  #sum def grids
  run = foreach(i=unique(group_by_vec)) %dopar% {
    flist = def.files.match[slice_vec[group_by_vec == i]]
    datetime_char = time$datetime[slice_vec[group_by_vec == i]]
    
    txt.filename <- paste0(tmp.dir.def, "do_sum_group_", datetime_char[1], "_",
                           datetime_char[length(datetime_char)],".txt")
    
    write.table(flist, file=txt.filename, quote=F, row.names=F, col.names=F, append=F)
    out.file <- paste0(tmp.dir.def, "sum_raster_", datetime_char[1], "_",
                       datetime_char[length(datetime_char)], ".tif")
    
    # call C++ sum program here
    # aruments are: 1. text file which lists geotiffs; 2. name of the output file; 3. NoData value 
    system(paste0("/opt/drought_anomaly/drought_anomaly_sum ", txt.filename, " ", out.file, " ", -9999  ))
  }
  
  #import summed rasters
  summed_def_rasters = list.files(tmp.dir.def, pattern = ".tif$", full.names = T)
  summed_def_raster_stack = stack(summed_def_rasters)
  
  #reformat data
  summed_def_vec = foreach(i=unique(group_by_vec)) %dopar% {
    library(raster)
    values(summed_def_raster_stack[[i]])
  }
  integrated_def = structure(summed_def_vec, row.names = c(NA, -length(summed_def_vec[[1]])), class = "data.frame")
  
  #calculate SEDI
  clusterExport(cl, c("git.dir"))
  clusterCall(cl, function() {source(paste0(git.dir,"sedi_fun.R"))})
  sedi_values = parApply(cl,integrated_def, 1, FUN = sedi_fun)
  stopCluster(cl)
  
  #create spatial template for current spi values
  current_sedi = summed_def_raster_stack[[1]]
  
  #allocate curent spi values to spatial template
  values(current_sedi) = sedi_values
  
  #write out archive raster
  writeRaster(current_sedi, paste0(archive.dir,"sedi_",time_fdates[length(time_fdates)],"_", 
                                   as.character(time_scale[t]),"_day" ,".tif"), format = "GTiff", overwrite = T)
  
  #write out raster as "current"
  writeRaster(current_sedi, paste0(write.dir,"current_sedi_", 
                                   as.character(time_scale[t]),"_day" ,".tif"), format = "GTiff", overwrite = T)
  toc()
  
  #clean up all temp data
  do.call(file.remove, list(list.files(tmp.dir.def, full.names = T)))  

  print(paste0(as.character(time_scale[t])," day SEDI calcualtion complete."))
}
